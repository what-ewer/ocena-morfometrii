{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure, segmentation, feature\n",
    "from vis_utils import load_volume, VolumeVisualizer, ColorMapVisualizer\n",
    "from scipy.ndimage import zoom\n",
    "from skimage.morphology import skeletonize_3d, binary_dilation\n",
    "from skimage import filters, morphology\n",
    "from scipy import signal\n",
    "from skimage.filters import frangi, sato\n",
    "from skimage.draw import line_nd\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from queue import PriorityQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREE_NAME = 'P01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading skeleton and skeleton_thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/P01/skeleton.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9ab1305c11dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msource_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./data/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mskeleton\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTREE_NAME\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/skeleton.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mskeleton_thickness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTREE_NAME\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/skeleton-thickness.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mreconstruction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTREE_NAME\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/reconstruction.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/P01/skeleton.npy'"
     ]
    }
   ],
   "source": [
    "source_dir = './data/'\n",
    "skeleton = np.load(source_dir + TREE_NAME + '/skeleton.npy')\n",
    "skeleton_thickness = np.load(source_dir + TREE_NAME + '/skeleton-thickness.npy')\n",
    "reconstruction = np.load(source_dir + TREE_NAME + '/reconstruction.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility visualisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_addition(base, base_with_addition):\n",
    "    base = (base.copy() > 0).astype(np.uint8)\n",
    "    addition = (base_with_addition > 0).astype(np.uint8)\n",
    "    addition[base == 1] = 0\n",
    "    ColorMapVisualizer(base + addition * 4).visualize()\n",
    "    \n",
    "def visualize_lsd(lsd_mask):\n",
    "    ColorMapVisualizer(lsd_mask.astype(np.uint8)).visualize()\n",
    "    \n",
    "def visualize_gradient(lsd_mask):\n",
    "    ColorMapVisualizer(lsd_mask.astype(np.uint8)).visualize(gradient=True)\n",
    "    \n",
    "def visualize_mask_bin(mask):\n",
    "    VolumeVisualizer((mask > 0).astype(np.uint8), binary=True).visualize()\n",
    "    \n",
    "def visualize_mask_non_bin(mask):\n",
    "    VolumeVisualizer((mask > 0).astype(np.uint8) * 255, binary=False).visualize()\n",
    "    \n",
    "def visualize_skeleton(mask, visualize_mask=True, visualize_both_versions=False):\n",
    "    skeleton = skeletonize_3d((mask > 0).astype(np.uint8))\n",
    "    if not visualize_mask or visualize_both_versions:\n",
    "        VolumeVisualizer(skeleton, binary=True).visualize()\n",
    "    if visualize_mask or visualize_both_versions:\n",
    "        skeleton = skeleton.astype(np.uint8) * 4\n",
    "        mask = (mask > 0).astype(np.uint8) * 3\n",
    "        mask[skeleton != 0] = 0\n",
    "        ColorMapVisualizer(skeleton + mask).visualize()\n",
    "\n",
    "def visualize_ultimate(lsd, base_mask):\n",
    "    visualize_lsd(lsd)\n",
    "    visualize_mask_non_bin(lsd)\n",
    "    visualize_addition(base_mask, lsd)\n",
    "    visualize_skeleton(lsd, visualize_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolving nodes mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolving leaves mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_skeleton(skeleton):   \n",
    "    new_skeleton = np.zeros(skeleton.shape)\n",
    "    skeleton_voxels = np.argwhere(skeleton)\n",
    "    \n",
    "    for voxel in skeleton_voxels:\n",
    "        x, y, z = tuple(voxel)\n",
    "        neighbours_count = 0\n",
    "        \n",
    "        for dx in [-1, 0, 1]:\n",
    "            for dy in [-1, 0, 1]:\n",
    "                for dz in [-1, 0, 1]:\n",
    "                    if dx == dy == dz == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    neighbour_x = x + dx\n",
    "                    neighbour_y = y + dy\n",
    "                    neighbour_z = z + dz\n",
    "                    if skeleton[neighbour_x, neighbour_y, neighbour_z] > 0:\n",
    "                        neighbours_count += 1\n",
    "                        \n",
    "        if neighbours_count > 1:\n",
    "            new_skeleton[x, y, z] = 1\n",
    "                        \n",
    "    return new_skeleton.astype(np.uint8)\n",
    "\n",
    "\n",
    "def mark_leaves(skeleton):\n",
    "    trimmed = trim_skeleton(skeleton)\n",
    "    leaves = skeleton - trimmed\n",
    "    return leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "leaves_mask = mark_leaves(skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resolving bifurcations mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_bifurcation_regions(skeleton):\n",
    "    padded_skeleton = np.pad(skeleton, 1)\n",
    "    bifurcations_map = np.zeros(padded_skeleton.shape)\n",
    "    \n",
    "    for skeleton_voxel in np.argwhere(padded_skeleton > 0):\n",
    "        x, y, z = tuple(skeleton_voxel)\n",
    "        kernel_radius = 1\n",
    "        kernel = np.ones((3, 3, 3))\n",
    "        kernel[1, 1, 1] = 0\n",
    "        \n",
    "        skeleton_slice = padded_skeleton[\n",
    "            x-kernel_radius:x+kernel_radius + 1,\n",
    "            y-kernel_radius:y+kernel_radius + 1,\n",
    "            z-kernel_radius:z+kernel_radius + 1\n",
    "        ]\n",
    "        \n",
    "        intersections = (skeleton_slice > 0) * kernel\n",
    "        bifurcations_map[x, y, z] = np.sum(intersections)\n",
    "        \n",
    "    return (bifurcations_map[1:-1, 1:-1, 1:-1] > 2).astype(np.uint8)\n",
    "\n",
    "\n",
    "def mark_nodes(skeleton):\n",
    "    bifurcation_map = mark_bifurcation_regions(skeleton)\n",
    "    leaves_map = mark_leaves(skeleton)\n",
    "    return bifurcation_map + leaves_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bifurcations_mask = mark_bifurcation_regions(skeleton)\n",
    "nodes_mask = ((bifurcations_mask + leaves_mask) > 0).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, coords):\n",
    "        self.coords = coords\n",
    "        self.edges = []\n",
    "        self.data = {}\n",
    "            \n",
    "    def add_edge(self, edge):\n",
    "        self.edges.append(edge)\n",
    "        \n",
    "    def get_neighbours(self):\n",
    "        return [e.node_a if e.node_a.coords != self.coords else e.node_b for e in self.edges]\n",
    "    \n",
    "    def copy_without_edges(self):\n",
    "        copied_node = Node(self.coords)\n",
    "        copied_node.data = self.data\n",
    "        return copied_node\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.data[key] = value\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.data[key]\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.coords)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Node {str(self.coords)}'\n",
    "        \n",
    "        \n",
    "class Edge:\n",
    "    def __init__(self, node_a, node_b):\n",
    "        self.node_a = node_a\n",
    "        self.node_b = node_b\n",
    "        self.data = {}\n",
    "        \n",
    "    def __setitem__(self, key, value):\n",
    "        self.data[key] = value\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.data[key]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Edge {self.node_a.coords} -> {self.node_b.coords}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph(skeleton, nodes_mask, skeleton_thickness):\n",
    "    nodes_labels = measure.label(nodes_mask)\n",
    "    nodes_props = measure.regionprops(nodes_labels)\n",
    "    print('nodes found (regions on nodes mask):', nodes_labels.max())\n",
    "    voxel_to_node = dict()\n",
    "    \n",
    "    for props in nodes_props:\n",
    "        if props.label < 1:\n",
    "            continue\n",
    "            \n",
    "        node = Node(tuple(props.coords[0]))\n",
    "        node['voxels'] = props.coords\n",
    "        node['thickness'] = skeleton_thickness[tuple(props.coords[0])]\n",
    "        \n",
    "        for c in props.coords:\n",
    "            voxel_to_node[tuple(c)] = node\n",
    "            \n",
    "    edges_mask = skeleton - nodes_mask\n",
    "    edges_labels = measure.label(edges_mask > 0)\n",
    "    print('edges found:', edges_labels.max())\n",
    "    \n",
    "    visited = np.zeros(skeleton.shape, dtype=np.bool)\n",
    "    \n",
    "    def find_touching_nodes(source_voxel):\n",
    "        touching_nodes = set()\n",
    "        queue = [source_voxel]\n",
    "        while len(queue) > 0:\n",
    "            x, y, z = queue.pop(0)\n",
    "            \n",
    "            for dx in [-1, 0, 1]:\n",
    "                for dy in [-1, 0, 1]:\n",
    "                    for dz in [-1, 0, 1]:\n",
    "                        if dx == dy == dz == 0:\n",
    "                            continue\n",
    "\n",
    "                        neighbour_x = x + dx\n",
    "                        neighbour_y = y + dy\n",
    "                        neighbour_z = z + dz\n",
    "                        if visited[neighbour_x, neighbour_y, neighbour_z]:\n",
    "                            continue\n",
    "                            \n",
    "                        potential_node = voxel_to_node.get((neighbour_x, neighbour_y, neighbour_z))\n",
    "                        if potential_node is not None:\n",
    "                            touching_nodes.add(potential_node)\n",
    "\n",
    "                        if edges_mask[neighbour_x, neighbour_y, neighbour_z] == 1:\n",
    "                            queue.append((neighbour_x, neighbour_y, neighbour_z))\n",
    "                            visited[neighbour_x, neighbour_y, neighbour_z] = True\n",
    "        return list(touching_nodes)\n",
    "       \n",
    "        \n",
    "    edges_props = measure.regionprops(edges_labels)\n",
    "    \n",
    "    edges = []\n",
    "    bad_edges = []\n",
    "    for props in edges_props:\n",
    "        edge_voxel = props.coords[0]\n",
    "        touching_nodes = find_touching_nodes(edge_voxel)\n",
    "        if len(touching_nodes) != 2:\n",
    "            print(f'bad edge found! touching nodes count: {len(touching_nodes)}')\n",
    "            bad_edges.append(props.coords)\n",
    "            continue\n",
    "            \n",
    "        edge = Edge(touching_nodes[0], touching_nodes[1])\n",
    "        edge['voxels'] = props.coords\n",
    "        edges.append(edge)\n",
    "    return edges, bad_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes found (regions on nodes mask): 7717\n",
      "edges found: 7931\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "bad edge found! touching nodes count: 1\n",
      "Number of bad edged found: 59\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edges, bad_edges = construct_graph(skeleton, nodes_mask, skeleton_thickness)\n",
    "print(\"Number of bad edged found:\", len(bad_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding root node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_nodes_list(edges):\n",
    "    nodes = {}\n",
    "    for e in edges:\n",
    "        nodes[e.node_a] = e.node_a.copy_without_edges()\n",
    "        nodes[e.node_b] = e.node_b.copy_without_edges()\n",
    "        \n",
    "    for e in edges:\n",
    "        new_edge = Edge(nodes[e.node_a], nodes[e.node_b])\n",
    "        new_edge.data = e.data\n",
    "        nodes[e.node_a].add_edge(new_edge)\n",
    "        nodes[e.node_b].add_edge(new_edge)\n",
    "        \n",
    "    return list(nodes.values())\n",
    "\n",
    "def find_tree_root_candidates(nodes, root_degree, thichness_tolerance):\n",
    "    proper_degree_nodes = [node for node in nodes if len(node.edges) == root_degree]\n",
    "    root_thickness = max(map(lambda node: node['thickness'], proper_degree_nodes))\n",
    "    root_candidates = [node for node in proper_degree_nodes if \n",
    "                       node['thickness'] >= root_thickness - thichness_tolerance]\n",
    "    return root_candidates\n",
    "\n",
    "def visualize_root(root, skeleton, mark_radius=2):\n",
    "    visualisation = skeleton.copy().astype(np.uint8)\n",
    "    for v in root['voxels']:\n",
    "            x, y, z = tuple(v)\n",
    "            visualisation[x - mark_radius: x + mark_radius, \n",
    "                          y - mark_radius: y + mark_radius, \n",
    "                          z - mark_radius: z + mark_radius] = 4\n",
    "    visualize_lsd(visualisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1 root candidate(s)\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "roots_degrees = {\n",
    "    'P01': 1,\n",
    "    'P05': 1,\n",
    "    'P12': 1,\n",
    "}\n",
    "\n",
    "root_thickness_tolerance = {\n",
    "    'P01': 0,\n",
    "    'P05': 9,\n",
    "    'P12': 0,\n",
    "}\n",
    "\n",
    "nodes = convert_to_nodes_list(edges)\n",
    "root_candidates = find_tree_root_candidates(nodes, roots_degrees.get(TREE_NAME, 1), \n",
    "                                            root_thickness_tolerance.get(TREE_NAME, 0))\n",
    "print(f'found {len(root_candidates)} root candidate(s)')\n",
    "\n",
    "candidates_indices = {\n",
    "    'P01': 0,\n",
    "    'P05': 6,\n",
    "    'P12': 0,\n",
    "}\n",
    "\n",
    "root = root_candidates[candidates_indices.get(TREE_NAME, 0)]\n",
    "visualize_root(root, skeleton, 5) # verify whether the proper node was selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing cycles (obtaining DAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dag_cycles(root): # TODO pomyśl o - przed node['thickness']\n",
    "    counter = 0\n",
    "    \n",
    "    new_root = root.copy_without_edges()\n",
    "    coords_to_old_parents = {}\n",
    "    coords_to_new_node = { new_root.coords: new_root }\n",
    "    \n",
    "    queue = PriorityQueue()\n",
    "    for node in root.get_neighbours():\n",
    "        coords_to_old_parents[node.coords] = [root]\n",
    "        queue.put(((-node['thickness'], counter), node))\n",
    "        counter += 1\n",
    "        \n",
    "    while not queue.empty():\n",
    "        _, node = queue.get()\n",
    "        \n",
    "        if coords_to_new_node.get(node.coords) is not None:\n",
    "            continue\n",
    "        \n",
    "        parent_candidates = coords_to_old_parents[node.coords]\n",
    "        proper_parent_thickness = min([p['thickness'] for p in parent_candidates])\n",
    "        proper_parent = [p for p in parent_candidates if p['thickness'] == proper_parent_thickness][0]\n",
    "        edge_from_parent = [e for e in proper_parent.edges if e.node_a == node or e.node_b == node][0]\n",
    "        \n",
    "        new_node = node.copy_without_edges()\n",
    "        new_parent = coords_to_new_node[proper_parent.coords]\n",
    "        new_edge = Edge(new_parent, new_node)\n",
    "        new_edge.data = edge_from_parent.data\n",
    "        new_parent.add_edge(new_edge)\n",
    "        \n",
    "        coords_to_new_node[new_node.coords] = new_node\n",
    "        \n",
    "        for neighbour in node.get_neighbours():\n",
    "            parents = coords_to_old_parents.get(neighbour.coords, [])\n",
    "            coords_to_old_parents[neighbour.coords] = parents + [node]\n",
    "            queue.put(((-neighbour['thickness'], counter), neighbour))\n",
    "            counter += 1\n",
    "            \n",
    "    return new_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 331 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clean_root = remove_dag_cycles(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing redundant nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_edges(a, b, node_a, node_b):\n",
    "        new_edge = Edge(node_a, node_b)\n",
    "        new_edge.data = a.data\n",
    "        new_edge['voxels'] = np.concatenate([a['voxels'], b.node_a['voxels'], b['voxels']])\n",
    "        return new_edge\n",
    "\n",
    "\n",
    "def remove_dag_redundant_nodes(root):\n",
    "    new_root = root.copy_without_edges()\n",
    "    for edge in root.edges:\n",
    "        new_neighbour = remove_dag_redundant_nodes(edge.node_b)\n",
    "        \n",
    "        if len(new_neighbour.edges) == 1:\n",
    "            merged_edge = merge_edges(edge, new_neighbour.edges[0], new_root, new_neighbour.edges[0].node_b)\n",
    "            new_root.add_edge(merged_edge)\n",
    "            \n",
    "        else:\n",
    "            new_edge = Edge(new_root, new_neighbour)\n",
    "            new_edge.data = edge.data\n",
    "            new_root.add_edge(new_edge)\n",
    "            \n",
    "    return new_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clean_root = remove_dag_redundant_nodes(clean_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining clean nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_with_dfs(root):\n",
    "    nodes = [root]\n",
    "    for e in root.edges:\n",
    "        if e.node_a != root:\n",
    "            print(e)\n",
    "        \n",
    "        nodes += get_nodes_with_dfs(e.node_b)\n",
    "        \n",
    "    return nodes\n",
    "\n",
    "\n",
    "def get_edges_with_dfs(root):\n",
    "    edges = []\n",
    "    for e in root.edges:\n",
    "        edges += [e]\n",
    "        edges += get_edges_with_dfs(e.node_b)\n",
    "        \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of nodes: 7337, # of edges: 7336\n"
     ]
    }
   ],
   "source": [
    "clean_nodes = get_nodes_with_dfs(clean_root)\n",
    "clean_edges = get_edges_with_dfs(clean_root)\n",
    "\n",
    "print(f'# of nodes: {len(clean_nodes)}, # of edges: {len(clean_edges)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating graph with basic metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reordering edges voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_edges_voxels(edge):\n",
    "    node_voxels = [tuple(voxel) for voxel in edge.node_a['voxels']]\n",
    "    edge_voxels = [tuple(voxel) for voxel in edge['voxels']]\n",
    "    all_voxels = node_voxels + edge_voxels\n",
    "    \n",
    "    queue = [node_voxels[0]]\n",
    "    sorted_voxels = [node_voxels[0]]\n",
    "    \n",
    "    while len(queue) != 0:\n",
    "        x, y, z = queue.pop(0)\n",
    "        \n",
    "        for dx in [-1, 0, 1]:\n",
    "            for dy in [-1, 0, 1]:\n",
    "                for dz in [-1, 0, 1]:\n",
    "                    if dx == dy == dz == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    neighbour = (x + dx, y + dy, z + dz)\n",
    "                    \n",
    "                    if (neighbour in sorted_voxels) or (neighbour not in all_voxels):\n",
    "                        continue\n",
    "                    \n",
    "                    sorted_voxels.append(neighbour)\n",
    "                    queue.append(neighbour)\n",
    "                    \n",
    "    sorted_edge_voxels = [voxel for voxel in sorted_voxels if voxel not in node_voxels]\n",
    "    edge['voxels'] = sorted_edge_voxels\n",
    "    \n",
    "def fix_edges_voxels(root):\n",
    "    edges = get_edges_with_dfs(root)\n",
    "    for edge in edges:\n",
    "        reorder_edges_voxels(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1057  153  665]]\n",
      "[(1056, 153, 666), (1055, 153, 666), (1054, 153, 666), (1053, 153, 666), (1052, 153, 666), (1051, 153, 667), (1050, 153, 667), (1049, 153, 667), (1048, 153, 667), (1047, 153, 667), (1046, 153, 668), (1045, 153, 668), (1044, 153, 668), (1043, 153, 668), (1042, 153, 668), (1041, 154, 668), (1040, 154, 668), (1039, 154, 669), (1038, 155, 668), (1037, 155, 669), (1036, 155, 669), (1035, 156, 669), (1034, 156, 669), (1033, 155, 670), (1032, 156, 670), (1031, 156, 670), (1030, 156, 670), (1029, 156, 670), (1028, 156, 671), (1027, 156, 671), (1026, 156, 672), (1025, 156, 672), (1024, 156, 672), (1023, 156, 673), (1022, 156, 673), (1021, 156, 674), (1020, 156, 674), (1019, 156, 675), (1018, 155, 675), (1017, 156, 675), (1016, 156, 676), (1015, 155, 676), (1014, 156, 676), (1013, 156, 676), (1012, 157, 676), (1011, 157, 677), (1010, 156, 678), (1009, 157, 677), (1008, 157, 678), (1007, 157, 678), (1006, 158, 678), (1005, 157, 679), (1004, 158, 679), (1003, 158, 680), (1002, 159, 680), (1001, 159, 680), (1000, 160, 680), (999, 159, 681), (998, 159, 681), (997, 160, 681), (996, 160, 682), (995, 161, 682), (994, 161, 683), (993, 161, 684), (992, 161, 684), (991, 161, 684), (990, 162, 684), (989, 162, 685), (988, 163, 685), (987, 163, 686), (986, 163, 686), (985, 164, 687), (984, 165, 687), (983, 165, 687)]\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fix_edges_voxels(clean_root)\n",
    "print(clean_root['voxels'])\n",
    "print(clean_root.edges[0]['voxels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edges and nodes thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_nodes_thickness(root, skeleton_thickness):\n",
    "    nodes = get_nodes_with_dfs(root)\n",
    "    for node in nodes:\n",
    "        thickness_list = [skeleton_thickness[tuple(coords)] for coords in node['voxels']]\n",
    "        node['thickness'] = np.mean(thickness_list)\n",
    "    \n",
    "\n",
    "def add_edges_thickness(root, skeleton_thickness):\n",
    "    edges = get_edges_with_dfs(root)\n",
    "    for edge in edges:\n",
    "        thickness_list = [skeleton_thickness[tuple(coords)] for coords in edge['voxels']]\n",
    "        edge['thickness_list'] = np.array(thickness_list)\n",
    "        edge['mean_thickness'] = np.mean(thickness_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 361 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47,\n",
       "       48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50,\n",
       "       50, 50, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52,\n",
       "       52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
       "       53, 53, 53, 53, 53, 53])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "fix_nodes_thickness(clean_root, skeleton_thickness)\n",
    "add_edges_thickness(clean_root, skeleton_thickness)\n",
    "clean_root.edges[0]['thickness_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### centroids and edges lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nodes_centroids(root):\n",
    "    nodes = get_nodes_with_dfs(root)\n",
    "    for node in nodes:\n",
    "        node['centroid'] = np.mean(node['voxels'], axis=0)\n",
    "\n",
    "        \n",
    "def calculate_edge_length(edge, chunk_length=1):\n",
    "    voxels = np.array(edge['voxels'])\n",
    "    needed_nans = (chunk_length - (len(voxels) % chunk_length)) % chunk_length\n",
    "    voxels = np.concatenate([voxels, np.full((needed_nans, 3), np.nan)])\n",
    "    \n",
    "    chunked_voxels = voxels.reshape(-1, chunk_length, 3)\n",
    "    \n",
    "    edge_centroids = np.nanmean(chunked_voxels, axis=1)\n",
    "    starting_centroid = edge.node_a['centroid']\n",
    "    ending_centroid = edge.node_b['centroid']\n",
    "    \n",
    "    centroids = np.concatenate([\n",
    "        starting_centroid[np.newaxis, ...],\n",
    "        edge_centroids,\n",
    "        ending_centroid[np.newaxis, ...]\n",
    "    ])\n",
    "    \n",
    "    squared_diffs = np.diff(centroids, axis=0) ** 2\n",
    "    squared_lengths = np.sum(squared_diffs, axis=1)\n",
    "    lengths = np.sqrt(squared_lengths)\n",
    "    total_length = np.sum(lengths)\n",
    "    \n",
    "    return total_length\n",
    "    \n",
    "\n",
    "def set_edges_length(root, chunk_length=1):\n",
    "    edges = get_edges_with_dfs(root)\n",
    "    for edge in edges:\n",
    "        edge['length'] = calculate_edge_length(edge, chunk_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.3454181093773\n",
      "Wall time: 768 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "set_nodes_centroids(clean_root)\n",
    "set_edges_length(clean_root, 2)\n",
    "print(clean_root.edges[0]['length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DAG object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAG:\n",
    "    def __init__(self, root, volume_shape):\n",
    "        self.root = root\n",
    "        self.nodes = get_nodes_with_dfs(root)\n",
    "        self.edges = get_edges_with_dfs(root)\n",
    "        self.volume_shape = volume_shape\n",
    "        self.data = {}\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.data[key] = value\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.data[key]\n",
    "        \n",
    "\n",
    "def save_dag(dag, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(dag, output)\n",
    "        \n",
    "\n",
    "def load_dag(filename):\n",
    "    with open(filename, 'rb') as input_:\n",
    "        dag = pickle.load(input_)\n",
    "        return dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag = DAG(clean_root, reconstruction.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAG visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spherical_kernel(outer_radius, thickness=1, filled=True):    \n",
    "    outer_sphere = morphology.ball(radius=outer_radius)\n",
    "    if filled:\n",
    "        return outer_sphere\n",
    "    \n",
    "    thickness = min(thickness, outer_radius)\n",
    "    \n",
    "    inner_radius = outer_radius - thickness\n",
    "    inner_sphere = morphology.ball(radius=inner_radius)\n",
    "    \n",
    "    begin = outer_radius - inner_radius\n",
    "    end = begin + inner_sphere.shape[0]\n",
    "    outer_sphere[begin:end, begin:end, begin:end] -= inner_sphere\n",
    "    return outer_sphere\n",
    "\n",
    "\n",
    "def print_kernels(image, nodes, value):\n",
    "    image = image.copy()\n",
    "    max_kernel_radius = int(max([node['thickness'] for node in nodes]))\n",
    "    kernels = [spherical_kernel(radius) for radius in range(max_kernel_radius + 1)]\n",
    "    \n",
    "    padded_image = np.pad(image, max_kernel_radius)\n",
    "    kernels_image = np.zeros(padded_image.shape)\n",
    "    \n",
    "    for node in nodes:\n",
    "        x, y, z = (coord + max_kernel_radius for coord in node.coords)\n",
    "        kernel_radius = int(node['thickness'])\n",
    "        kernel = kernels[kernel_radius]\n",
    "        \n",
    "        mask_slice = kernels_image[\n",
    "            x-kernel_radius:x+kernel_radius + 1,\n",
    "            y-kernel_radius:y+kernel_radius + 1,\n",
    "            z-kernel_radius:z+kernel_radius + 1\n",
    "        ]\n",
    "        \n",
    "        mask_slice[:] = np.logical_or(mask_slice, kernel)\n",
    "            \n",
    "    kernels_image = kernels_image[\n",
    "        max_kernel_radius:-max_kernel_radius,\n",
    "        max_kernel_radius:-max_kernel_radius,\n",
    "        max_kernel_radius:-max_kernel_radius\n",
    "    ]\n",
    "    \n",
    "    image[kernels_image == 1] = value\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_nodes(image, nodes, value=2):\n",
    "    nodes_image = print_kernels(image, nodes, value)\n",
    "    return nodes_image\n",
    "\n",
    "    \n",
    "def draw_edges(image, edges, value='mean_thickness', interpolate=True):\n",
    "    image = image.copy()\n",
    "\n",
    "    for i, edge in enumerate(edges):\n",
    "        if type(value) == str:\n",
    "            fill_value = edge[value]\n",
    "        else:\n",
    "            fill_value = value\n",
    "        \n",
    "        if interpolate:\n",
    "            image[line_nd(edge.node_a.coords, edge.node_b.coords)] = fill_value\n",
    "        else:\n",
    "            for v in edge['voxels']:\n",
    "                image[tuple(v)] = fill_value\n",
    "        \n",
    "    return image\n",
    "\n",
    "def draw_central_line(image, dag):\n",
    "    image_with_edges = draw_edges(image, dag.edges, value=1, interpolate=False)\n",
    "    for n in dag.nodes:\n",
    "        for v in n['voxels']:\n",
    "            image_with_edges[tuple(v)] = 1\n",
    "        \n",
    "    return image_with_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization = np.zeros(skeleton.shape)\n",
    "visualization = draw_nodes(visualization, dag.nodes, 25)\n",
    "visualization = draw_edges(visualization, dag.edges, value='mean_thickness')\n",
    "visualize_gradient(visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization = np.zeros(skeleton.shape)\n",
    "visualization = draw_edges(visualization, dag.edges, value='length')\n",
    "visualize_gradient(visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_line = draw_central_line(np.zeros(skeleton.shape), dag)\n",
    "visualize_addition(central_line, skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dag(dag, source_dir + TREE_NAME + '/dag.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
